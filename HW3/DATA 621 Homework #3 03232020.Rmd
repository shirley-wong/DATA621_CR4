---
title: 'DATA 621 Homework #3'
author: 'Critical Thinking Group 4: Rajwant Mishra, Priya Shaji, Debabrata Kabiraj,
  Isabel Ramesar, Sin Ying Wong and Fan Xu'
date: "3/15/2020"
output:
  rmdformats::readthedown:
    code_folding: hide
    df_print: paged
    highlight: tango
    number_sections: no
    smooth_scroll: yes
    theme: united
    toc_collapsed: yes
    toc_depth: 5
    toc_float: yes
  word_document:
    toc: yes
    toc_depth: '5'
  pdf_document:
    extra_dependencies:
    - geometry
    - multicol
    - multirow
  html_document:
    df_print: paged
    toc: yes
    toc_collapsed: yes
    toc_float: yes
theme: lumen
number_sections: yes
toc_depth: 3
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r, warning = FALSE, message=FALSE}
library(tidyverse)
library(kableExtra)
library(visdat)
library(DT)
library(psych)
library(corrplot)
library(MASS)
```

# Overview
In this homework assignment, you will explore, analyze and model a data set containing information on crime for various neighborhoods of a major city. Each record has a response variable indicating whether or not the crime rate is above the median crime rate (1) or not (0).

Your objective is to build a binary logistic regression model on the training data set to predict whether the neighborhood will be at risk for high crime levels. You will provide classifications and probabilities for the evaluation data set using your binary logistic regression model. You can only use the variables given to you (or variables that you derive from the variables provided). Below is a short description of the variables of interest in the data set:

| Variable Name | Definition                                                                   | Variable Type |
|---------------|------------------------------------------------------------------------------|---------------|
| zn            | proportion of residential land zoned for large lots (over 25000 square feet) | predictor     |
| indus         | proportion of non-retail business acres per suburb                           | predictor     |
| chas          | a dummy var. for whether the suburb borders the Charles River (1) or not (0) | predictor     |
| nox           | nitrogen oxides concentration (parts per 10 million)                         | predictor     |
| rm            | average number of rooms per dwelling                                         | predictor     |
| age           | proportion of owner-occupied units built prior to 1940                       | predictor     |
| dis           | weighted mean of distances to five Boston employment centers                 | predictor     |
| rad           | index of accessibility to radial highways                                    | predictor     |
| tax           | full-value property-tax rate per $10,000                                     | predictor     |
| ptratio       | pupil-teacher ratio by town                                                  | predictor     |
| black         | 1000(Bk - 0.63)2 where Bk is the proportion of blacks by town                | predictor     |
| lstat         | lower status of the population (percent)                                     | predictor     |
| medv          | median value of owner-occupied homes in $1000s                               | predictor     |
| target        | whether the crime rate is above the median crime rate (1) or not (0)         | response      |

# Deliverables
A write-up of your solutions submitted in PDF format. Assigned prediction (probabilities, classifications) for the evaluation data set. Use 0.5 threshold.

```{r, eval=FALSE, warning=FALSE, message=FALSE, echo=FALSE, results='hide'}
#packages <- c("DT","data.table","kableExtra","knitr","stringr","tidyr","tidyverse","dplyr","psych","reshape","mice","caret","e1071","Hmisc","visdat","corrplot","bbmle","DMwR","scatterplot3d","car","broom","corrplot")
# install.packages(packages, repos="http://cran.us.r-project.org", dependencies=TRUE)
# invisible(lapply(packages, library, character.only = T))
#library(DT)
#library(data.table)
#library(kableExtra)
#library(knitr)
#library(tidyverse)
#library(psych)
#library(Hmisc)
#library(visdat)
#library(corrplot)
#library(bbmle)
#library(DMwR)
#library(scatterplot3d)
#library(car)
#library(broom)
#library(corrplot)
```

# Data Exploration

```{r Import Dataset, message=FALSE, warning=FALSE}
data_t <- read_csv('https://raw.githubusercontent.com/Rajwantmishra/DATA621_CR4/master/HW3/crime-training-data_modified.csv') %>%
  dplyr::select(target, everything())

data_e <- read_csv('https://raw.githubusercontent.com/Rajwantmishra/DATA621_CR4/master/HW3/crime-evaluation-data_modified.csv')
```


## Missing Values & Data Type Check

Two data sets are given. One is the `training set`, which includes 12 candidate predictors, 1 response variable, and 466 observations without missing values (eg: NA, NULL or ''). The other one is the `evaluation set`, which includes 12 candidate predictors only, 40 observations without missing values. However, the variable `black`, which is described in the overview section, is not presented in the data set.

Among the 12 candidate predictors, 1 is categorical (`chas`), the other 11 are continuous numerical. The response variable `target` is categorical.


```{r, glimpse training set, warning=FALSE, message=FALSE}
glimpse(data_t)
```
<center>Table 1: Glimpse of `training set`</center>


```{r, glimpse evaluation set, warning=FALSE, message=FALSE}
glimpse(data_e)
```
<center>Table 2: Glimpse of `evaluation set`</center>


```{r, missing values & data type check, warning=FALSE, message=FALSE}
library(gridExtra)
p_t_dt <- vis_dat(data_t)
p_t_m <- vis_miss(data_t)
p_e_dt <- vis_dat(data_e)
p_e_m <- vis_miss(data_e)
grid.arrange(p_t_m,p_e_m, p_t_dt,p_e_dt,ncol = 2, 
             widths = c(1,1),
             heights = c(1.5,1),
             top = 'Missing Values & Data Type Check
             Training Set                                                     Evaluation Set')


```
<center>Figure 1: Missing Values & Data Type Check</center>


## Data Statistics Summary

A binary logistic regression model is to be built using the `training set`, therefore the `training set` is used for the following data exploration.

The data types in the raw data set are all 'doubles', however the candidate predictor `chas` and the response variable `target` are categorical, therefore, we update the data types of these two variables to 'factors'. 

```{r summary}
data_t_mod <- data_t %>% 
  mutate(chas = as.factor(chas),
         target = as.factor(target)) %>%
  dplyr::select(target, everything())
DT::datatable(data_t_mod)
```
<center>Table 3: `training set`</center>

<br/>
<br/>
The statistics of all variables are list below:
```{r statistics summary}
summary(data_t_mod)
```

The box plot shows that outliners exist in variables `zn`, `rm`, `dis`, `istat`, `medv`. 


```{r Boxplot on training set, warning=FALSE, message=FALSE}
data_t %>%
  scale() %>%
  as.data.frame() %>%
  stack() %>%
  ggplot(aes(x = ind, y = values)) +
  geom_boxplot(fill = 'deeppink4') +
  labs(title = 'Boxplot: Scaled Training Set',
       x = 'Variables',
       y = 'Normalized_Values')+
  theme(panel.background = element_rect(fill = 'grey'))  
```
<center>Figure 2: Boxplot: Scaled Training Set</center>

The histogram shows that variables `zn`,`nox`, `dis`, `istat`, `medv` are right skewed; `age`, `ptratio` are left skewed;  `rad`, `tax` are bimodal; `target`, `chas` are categorical however `target` is close to unbias while `chas` is highly biased; the rest are close to normal. 

```{r,Histogram on training set, warning=FALSE, message=FALSE}
data_t %>%
  scale() %>%
  as.data.frame() %>%
  stack() %>%
  ggplot(aes(x = values)) +
  geom_histogram(fill = 'deeppink4', color = 'black') +
  labs(title = 'Histogram: Scaled Training Set')+
  theme(panel.background = element_rect(fill = 'grey'))+
  facet_wrap(~ind, scale='free', ncol = 4)

```
<center>Figure 3: Histomgram: Training Set</center>

<br/>
<br/>
The correlation matices below show that the response variable `target` has strong positive relationship (>=0.6) with variables `rad`,`tax`,`age`,`indus`,`nox`, and strong negative relationship (<=-0.6) with variable `dis`. 

Meanwhile, it worths notice that some pairs of candidate predictors have strong correlationship, such as `rad` and `tax` (0.92), `indus` and `nox` (0.76), `nox` and `dis` (-0.77), etc.,.  

```{r correlation hitmap}
data_t %>%
  cor() %>%
  #corrplot(method = "pie", type = "upper", order = 'hclust', tl.col = "black", diag = FALSE, bg= 'grey', col = #colorRampPalette(c('deeppink4','white','steelblue1'))(100))
  corrplot.mixed(upper = 'pie', lower = 'number', order = 'hclust', tl.col = "black")
```


<center>Figure 4: Correlation Pie Chart: Training Set</center>
```{r correlation matrix}
pairs.panels(data_t_mod)
```
<center>Figure 5: Correlation Matrix: Training Set</center>



## Consolidated Data Dictionary

As a summary of the data exploration process, a data dictionary is created as below:

```{r data dictionary}
data_stat <- data_t %>% 
  dplyr::select(-target,-chas) %>%
  gather() %>%
  group_by(key) %>%
  summarise(Mean = mean(value),
            Median = median(value),
            Max = max(value),
            Min = min(value),
            SD = sd(value))

data_cor <- data_t %>%
  cor() %>%
  as.data.frame() %>% 
  dplyr::select(target) %>% 
  rownames_to_column('Variable') %>%
  dplyr::rename(Correlation_vs_Response = target)

data_t %>% 
  gather() %>%
  dplyr::select(key) %>%
  unique() %>%
  dplyr::rename(Variable = key) %>%
  mutate(Description = c('whether the crime rate is above the median crime rate (1) or not (0)',
                         'proportion of residential land zoned for large lots (over 25000 square feet)',
                         'proportion of non-retail business acres per suburb',
                         'a dummy var. for whether the suburb borders the Charles River (1) or not (0)',
                         'nitrogen oxides concentration (parts per 10 million)',
                         'average number of rooms per dwelling',
                         'proportion of owner-occupied units built prior to 1940',
                         'weighted mean of distances to five Boston employment centers',
                         'index of accessibility to radial highways',
                         'full-value property-tax rate per $10,000',
                         'pupil-teacher ratio by town',
                         'lower status of the population (percent)',
                         'median value of owner-occupied homes in $1000s'),
         Var_Type_1 = if_else(Variable %in% c('target','chas'), 'categorical','continuous numerical'),
         Var_Type_2 = if_else(Variable == 'target', 'response', 'predictor'),
         Missing_Value = 'No') %>%
  left_join(data_stat, by = c('Variable'='key')) %>%
  left_join(data_cor, by = 'Variable') %>%
  mutate_if(is.numeric,round,2) %>%
  kable() %>%
  kable_styling(bootstrap_options = c("striped", "hover", "condensed", "responsive"),full_width = F)
  
  

```
<center>Table 4: Data Dictionary</center>


# Data Preparation

## Re-scale Data

The data set contains variables of different measurements, such as percentage, distance, money values, etc.,. To put all the predictors and the response on a comparable scale, the they are all normalized with mean = 0 and SD = 1.
```{r re-scale}
data_rescaled <- scale(data_t_mod[c(2,3,5:13)]) %>%
  as.data.frame() %>%
  cbind(data_t_mod[c(1,4)]) %>%
  dplyr::select(target, zn, indus, chas, everything())

DT::datatable(data_rescaled)
```
<center>Table 5: Rescaled `training set`</center>

# Buikd Models

draft ...
```{r}
fit1 <- glm(target ~ ., data = data_t_mod, family = "binomial")
summary(fit1)
```

```{r}
fit2 <- glm(target ~ ., data = data_rescaled, family = "binomial")
summary(fit2)
```


# Select Models
